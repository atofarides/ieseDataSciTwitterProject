if(data$TOT.DEL.MIN[i] > 0) {
data$IF.DEL[i] = as.character(1)
} else {
data$IF.DEL[i] = 0
}
data$IF.DEL[is.na(data$IF.DEL)] = 0
# DELAY > 2HR Y/N
for (i in 1:nrow(data))
if(data$TOT.DEL.MIN[i] > 120) {
data$IF.DEL2HR[i] = as.character(1)
} else {
data$IF.DEL2HR[i] = 0
}
data$IF.DEL2HR[is.na(data$IF.DEL)] = 0
# Convert Del code to character
data$DEL1 = as.character(data$DEL1)
data$DEL2 = as.character(data$DEL2)
str(data)
# Linear Regression
fm = IF.DEL ~ MON + ACTYPE + FLT
mod = lm(formula = fm, data = data)
summary(mod)
data$MON = as.character(month(data$Ã¯..ATD.DATE))
# DELAY Y/N
for (i in 1:nrow(data))
if(data$TOT.DEL.MIN[i] > 0) {
data$IF.DEL[i] = as.character(1)
} else {
data$IF.DEL[i] = 0
}
data$IF.DEL[is.na(data$IF.DEL)] = 0
# DELAY > 2HR Y/N
for (i in 1:nrow(data))
if(data$TOT.DEL.MIN[i] > 120) {
data$IF.DEL2HR[i] = as.character(1)
} else {
data$IF.DEL2HR[i] = 0
}
data$IF.DEL2HR[is.na(data$IF.DEL)] = 0
# Convert Del code to character
data$DEL1 = as.character(data$DEL1)
data$DEL2 = as.character(data$DEL2)
str(data)
# Linear Regression
fm = IF.DEL ~ MON + ACTYPE + FLT
mod = lm(formula = fm, data = data)
summary(mod)
fm = IF.DEL2HR ~ MON + ACTYPE + FLT
mod = lm(formula = fm, data = data)
summary(mod)
data2017 = read.csv(file="c:/Users/anton/OneDrive/Documents/IESE/Term 5 Courses/AMORE/Volotea/1a. Volotea OTP 2017 - SUMMER.csv", header=TRUE, stringsAsFactors=FALSE)
data2018 = read.csv(file="c:/Users/anton/OneDrive/Documents/IESE/Term 5 Courses/AMORE/Volotea/1b. Volotea OTP 2018 - SUMMER.csv", header=TRUE, stringsAsFactors=FALSE)
data = rbind.data.frame(data2017,data2018,make.row.names = FALSE, stringsAsFactors = FALSE)
data2018 = read.csv(file="c:/Users/anton/OneDrive/Documents/IESE/Term 5 Courses/AMORE/Volotea/1b. Volotea OTP 2018 - SUMMER.csv", header=TRUE, stringsAsFactors=FALSE)
str(data2018)
costATG = c(80, 400, 1230, 4040, 7980, 12800, 25030, 40550, 59200)
data2018 = read.csv(file="c:/Users/anton/OneDrive/Documents/IESE/Term 5 Courses/AMORE/Volotea/1b. Volotea OTP 2018 - SUMMER.csv", header=TRUE, stringsAsFactors=FALSE)
str(data2018)
flightsType1 <- data2018$DEP!=c("ACE","FUE","LPA","TFS")
flightsType1 <- data2018$DEP!="ACE"
flightsType1 <- data2018$DEP!=c("ACE","FUE","LPA","TFS")
flightsType1 <- data2018[!(data2018$DEP!="ACE"&data2018$DEP!="FUE"&data2018$DEP!="LPA"&data2018$DEP!="TFS"),]
flightsType1 <- data2018[(data2018$DEP!="ACE"&data2018$DEP!="FUE"&data2018$DEP!="LPA"&data2018$DEP!="TFS"),]
flightsType1 <- data2018[(data2018$DEP!="ACE"&data2018$DEP!="FUE"&data2018$DEP!="LPA"&data2018$DEP!="TFS"&data2018$TOT.DEL.ARR>=02:00),]
flightsType1 <- data2018[(data2018$DEP!="ACE"&data2018$DEP!="FUE"&data2018$DEP!="LPA"&data2018$DEP!="TFS"&data2018$TOT.DEL.ARR>="02:00"),]
flightsType1 <- data2018[(data2018$DEP!="ACE"
&data2018$DEP!="FUE"
&data2018$DEP!="LPA"
&data2018$DEP!="TFS"
&data2018$ARR!="ACE"
&data2018$ARR!="FUE"
&data2018$ARR!="LPA"
&data2018$ARR!="TFS"
&data2018$TOT.DEL.ARR>="02:00"),]
passengersType1 <- sum(flightsType1$PAX)
passengersType1 <- sum(flightsType1$PAX)
passengersType1 <- sum(as.numeric(flightsType1$PAX))
flightsType1 <- na.omit(flightsType1$PAX)
passengersType1 <- sum(as.numeric(flightsType1$PAX))
passengersType1 <- sum(as.numeric(flightsType1))
flightsType1 <- flightsType1[flightsType1$PAX>=0,]
flightsType1 <- data2018[(data2018$DEP!="ACE"
&data2018$DEP!="FUE"
&data2018$DEP!="LPA"
&data2018$DEP!="TFS"
&data2018$ARR!="ACE"
&data2018$ARR!="FUE"
&data2018$ARR!="LPA"
&data2018$ARR!="TFS"
&data2018$TOT.DEL.ARR>="02:00"),]
flightsType1 <- flightsType1[flightsType1$PAX>=0,]
passengersType1 <- sum(as.numeric(flightsType1))
passengersType1 <- sum(flightsType1$PAX)
passengersType1 <- sum(as.numeric(flightsType1$PAX)
passengersType1 <- sum(as.numeric(flightsType1$PAX))
passengersType1 <- sum(as.numeric(flightsType1$PAX))
flightsType1 <- data2018[(data2018$DEP!="ACE"
&&data2018$DEP!="FUE"
&&data2018$DEP!="LPA"
&&data2018$DEP!="TFS"
&&data2018$ARR!="ACE"
&&data2018$ARR!="FUE"
&&data2018$ARR!="LPA"
&&data2018$ARR!="TFS"
&&data2018$TOT.DEL.ARR>="02:00"),]
flightsType1 <- data2018[(data2018$DEP!="ACE"
&data2018$DEP!="FUE"
&data2018$DEP!="LPA"
&data2018$DEP!="TFS"
&data2018$ARR!="ACE"
&data2018$ARR!="FUE"
&data2018$ARR!="LPA"
&data2018$ARR!="TFS"
&data2018$TOT.DEL.ARR>="02:00"),]
flightsType1 <- data2018[(data2018$DEP!="ACE"
&data2018$DEP!="FUE"
&data2018$DEP!="LPA"
&data2018$DEP!="TFS"
&data2018$ARR!="ACE"
&data2018$ARR!="FUE"
&data2018$ARR!="LPA"
&data2018$ARR!="TFS"
&&data2018$TOT.DEL.ARR>="02:00"),]
flightsType1 <- data2018[(data2018$DEP!="ACE"
&&data2018$DEP!="FUE"
&&data2018$DEP!="LPA"
&&data2018$DEP!="TFS"
&&data2018$ARR!="ACE"
&&data2018$ARR!="FUE"
&&data2018$ARR!="LPA"
&&data2018$ARR!="TFS"
&data2018$TOT.DEL.ARR>="02:00"),]
flightsType1 <- data2018[(
data2018$TOT.DEL.ARR>="02:00"),]
flightsType2 <- data2018[(data2018$DEP=="ACE"
|data2018$DEP=="FUE"
|data2018$DEP=="LPA"
|data2018$DEP=="TFS"
|data2018$ARR=="ACE"
|data2018$ARR=="FUE"
|data2018$ARR=="LPA"
|data2018$ARR=="TFS"
|data2018$TOT.DEL.ARR>="03:00"),]
getwd()
source('~/GitHub/ieseDataSciProject/golf.r')
warnings()
source('~/GitHub/ieseDataSciProject/golf.r')
source('~/GitHub/ieseDataSciProject/golf.r')
View(players)
library("magrittr")
source('~/GitHub/ieseDataSciProject/golf.r')
#Loading libraries
library("XML")
library("rvest")
library("tidyverse")
library("stringr")
library("ggplot2")
# Initiate global variables
playersAllYears <- data.frame(
Year = numeric(),
Rank = numeric(),
ID = factor(),
Name = character(),
Country = factor(),
OfficialMoney = numeric(),
EventsPlayed = numeric()
)
#year <- seq(from = 2018, to = 2000, by = -1)
y <- c("2018")
url <- c('http://www.lpga.com/statistics/money/official-money?year=')
colTypes <- c("numeric","character","character","numeric")
#for (y in year) {
print(paste("Processing data for year",y))
# Defining working URL
tableURL <- paste(url,y,sep = "")
# Players' Table Text scraped
players <- readHTMLTable(tableURL, colClasses = colTypes, stringsAsFactors = FALSE, as.data.frame = TRUE, which = 1)
names(players)[3:4] <- c("OfficialMoney", "EventsPlayed")
str(players)
# Converting official money to numeric to enable analysis
players$`OfficialMoney`%<>% gsub("\\$|,","") %>%
as.numeric()
View(players)
# Identifying erroneous spacing in player profile links, fixing
if (str_detect(read_html(tableURL),"/players/.+ [a-z0-9/-]*>")){
print(paste("Errors identified in table of year", y,"... Fixing!"))
# Reading HTML nodes
golfHTML <- readLines(tableURL) %>%
sapply(str_replace, "(/players/.+) ([a-z0-9/-]*>)","\\1-\\2") %>%
paste(collapse = "") %>%
read_html()
} else {
golfHTML <- read_html(tableURL)
}
# Reading profile links
golfPlayersNodes <- html_nodes(golfHTML, xpath = "//tbody/tr/td[contains(@class, 'table-content left')]/a")
# Identifying missing link attributes
missingProfileLinks <- html_attrs(golfPlayersNodes) %>%
sapply(is_empty) %>%
which()-1
# Extracting player ID
playersID <- html_attrs(golfPlayersNodes) %>%
unlist() %>%
strsplit("/") %>%
unlist() %>%
matrix(nrow=length(), byrow = TRUE) [,4]
# Extracting player ID
playersID <- html_attrs(golfPlayersNodes) %>%
unlist() %>%
strsplit("/") %>%
unlist() %>%
matrix(nrow=length(golfPlayersNodes), byrow = TRUE) [,4]
dim(golfPlayersNodes)
length(golfPlayersNodes)
source('~/GitHub/ieseDataSciProject/golf.r')
# Adding NAs for missing profiles
for (i in missingProfileLinks){
playersID %<>% append(., NA, after = i)
}
source('~/GitHub/ieseDataSciProject/golf.r')
# Adding NAs for missing profiles
for (i in missingProfileLinks){
playersID %<>% append(., NA, after = i)
}
source('~/GitHub/ieseDataSciProject/golf.r')
View(players)
source('~/GitHub/ieseDataSciProject/golf.r')
source('~/GitHub/ieseDataSciProject/golf.r')
View(players)
length(golfPlayersNodes)
# Extracting player ID
playersID <- html_attrs(golfPlayersNodes) %>%
unlist() %>%
strsplit(.,"/") %>%
unlist() %>%
matrix(.,nrow=length(golfPlayersNodes), byrow = TRUE) [,4]
html_attrs(golfPlayersNodes)
unlist(html_attrs(golfPlayersNodes))
strsplit(unlist(html_attrs(golfPlayersNodes)),"/")
unlist(strsplit(unlist(html_attrs(golfPlayersNodes)),"/"))
matrix(unlist(strsplit(unlist(html_attrs(golfPlayersNodes)),"/")), nrow = length(golfPlayersNodes), byrow = TRUE)
length(unlist(html_attrs(golfPlayersNodes)))
source('~/GitHub/ieseDataSciProject/golf.r')
length(golfPlayersNodes) - length(missingProfileLinks)
source('~/GitHub/ieseDataSciProject/golf.r')
source('~/GitHub/ieseDataSciProject/golf.r')
matrix(unlist(strsplit(unlist(html_attrs(golfPlayersNodes)),"/")), nrow = length(golfPlayersNodes), byrow = TRUE)
matrix(unlist(strsplit(unlist(html_attrs(golfPlayersNodes)),"/")), nrow = length(golfPlayersNodes)-length(missingProfileLinks), byrow = TRUE)
source('~/GitHub/ieseDataSciProject/golf.r')
source('~/GitHub/ieseDataSciProject/golf.r')
source('~/GitHub/ieseDataSciProject/golf.r')
source('~/GitHub/ieseDataSciProject/golf.r')
source('~/GitHub/ieseDataSciProject/golf.r')
source('~/GitHub/ieseDataSciProject/golf.r')
getwd()
# Setting working directory #
#wd = 'C:/Users/mcanela/Dropbox (Personal)/code/lpga/html files'
wd = paste(getwd(),"Github/ieseDataSciLPGAProject", sep="")
setwd(wd)
# Setting working directory #
#wd = 'C:/Users/mcanela/Dropbox (Personal)/code/lpga/html files'
wd = paste(getwd(),"/Github/ieseDataSciLPGAProject", sep="")
setwd(wd)
# Capturing the HTML file #
url0 = 'http://www.lpga.com/statistics/money/official-money?year='
?paste0
# Setting working directory #
#wd = 'C:/Users/mcanela/Dropbox (Personal)/code/lpga/html files'
wd = paste0(getwd(),"/Github/ieseDataSciLPGAProject")
setwd(wd)
# Setting working directory #
#wd = 'C:/Users/mcanela/Dropbox (Personal)/code/lpga/html files'
wd = paste(getwd(),"/Github/ieseDataSciLPGAProject", sep="")
setwd(wd)
# Setting working directory #
#wd = 'C:/Users/mcanela/Dropbox (Personal)/code/lpga/html files'
wd = paste(getwd(),"/Github/ieseDataSciLPGAProject", sep="")
for(y in 2018:2018) {
url = paste0(url0, y)
filename = paste0('lpga', '-', y, '.html')
download.file(url, destfile=filename)
}
# Resources #
library(XML)
library(stringr)
del = function(x,y) str_replace_all(x, y, '')
?str_replace_all
# Scraping function #
scrape = function(y) {
# Reading the file
doc = paste0('lpga-', y, '.html')
docstring = readChar(doc, nchar=file.info(doc)$size)
# Table
df = readHTMLTable(doc, which=1, stringsAsFactors=FALSE)
df[, 3] = del(df[, 3], '[$]|,')
# Player ID
page = htmlParse(doc)
PlayerID = xpathApply(doc=page, path='//div[@class="flag"]/parent::a',
fun=xmlGetAttr, 'href')
PlayerID = lapply(PlayerID, function(x) ifelse(length(x)==0, NA, x))
df$PlayerID = unlist(PlayerID)
df$PlayerID = del(df$PlayerID, '[^0-9]')
# Country
Country = xpathApply(doc=page, path='//div[@class="flag"]/child::img',
fun=xmlGetAttr, 'src')
Country = unlist(Country)
for(i in 1:(nrow(df)-1)) {
if(is.na(df$PlayerID[i])){
Country = c(Country[1:(i-1)], NA, Country[i:length(Country)])
}
}
df$Country = Country[1:nrow(df)]
df$Country = del(df$Country, '.+/')
df$Country = del(df$Country, '[.].+?.+')
# Exporting to csv2
df = df[, c(1, 5, 2, 6, 3, 4)]
names(df)[2] = 'Player ID'
filename = paste0('lpga-', y, '.csv')
write.csv2(df, file=filename, row.names=FALSE, quote=FALSE, na='')
}
# Scraping pages #
for(y in 2000:2018) scrape(y)
source('~/GitHub/ieseDataSciLPGAProject/lpga.R')
getwd()
source('~/GitHub/ieseDataSciLPGAProject/lpga.R')
# Reading the file
doc = paste0('lpga-', y, '.html')
docstring = readChar(doc, nchar=file.info(doc)$size)
dir()
source('~/GitHub/ieseDataSciLPGAProject/lpga.R')
source('~/GitHub/ieseDataSciLPGAProject/golf.r')
source('~/GitHub/ieseDataSciLPGAProject/golf.r')
setwd(~/Github/ieseDataSciTwitterProject)
setwd(~Github/ieseDataSciTwitterProject)
setwd("~/Github/ieseDataSciTwitterProject")
install(rTweet)
install.packages(rTweet)
install.packages(Rtweet)
install.packages("Rtweet")
install.packages("rtweet")
# Load libraries
library("rtwitter")
# Load libraries
library("rtweet")
## install rtweet package if it's not already
if (!requireNamespace("rtweet", quietly = TRUE)) {
install.packages("rtweet")
}
# Load libraries
library("rtweet")
library("tidyverse")
library("stringr")
library("magrittr")
?search_tweets
# Getting tweet for airline
test <- search_tweets("@united", n=100)
View(test)
# Getting tweet for airline
test <- search_tweets("SELECT * WHERE text CONTAINS \"@united\" AND created_at <> 2018-11 AND 2019-2", retryonratelimit = TRUE)
# Getting tweet for airline
test <- search_tweets("@united", retryonratelimit = TRUE)
# Getting tweet for airline
test <- search_tweets("@united")
# Getting tweet for airline
test <- search_tweets("@united", n=18000)
View(test)
min(test$created_at)
# Getting tweet for airline
test <- search_tweets("@united", n=300000, retryonratelimit = TRUE)
# Getting tweet for airline
test <- search_tweets("@united OR #united", n=100000, retryonratelimit = TRUE)
# Getting tweet for airline
test <- search_tweets("@united OR #united", n=10000, retryonratelimit = TRUE, lang = "en")
if (!requireNamespace("twitteR", quietly = TRUE)) {
install.packages("twitteR")
}
library("twitteR")
consumer_key <- "BujsomF1UhhKKWvITZOwF5Zsc"
consumer_secret <-"fTvj08eVKFFYXwxnWBms2RvZWtN5UISFr5utcDky2Ykux89aoR"
access_token <- "75392836-uvLbtpjwBMZcFHbXFssyNT0aw10AOx25hDHrVBVuU"
access_secret <- "niaDNQ4qHLl51s6CCaWfHCF8hmsczsx1bg9qM472P4qmX"
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
# Getting tweet for airline
test <- searchTwitter("@united OR #united", since = 2018-12-15)
# Getting tweet for airline
test <- searchTwitter("@united+#united", since = 2018-12-15)
# Getting tweet for airline
test <- searchTwitter("@united+#united", since = "2018-12-15")
View(test)
# Getting tweet for airline
test <- searchTwitter("@united+#united", since = "2018-12-15", until = "2019-05-21")
# Getting tweet for airline
test <- searchTwitter("@united+#united", n=10000, since = "2018-12-15", until = "2019-05-21")
## install rtweet package if it's not already
if (!requireNamespace("rtweet", quietly = TRUE)) {
install.packages("rtweet")
}
# Load libraries
library("rtweet")
library("tidyverse")
library("stringr")
library("magrittr")
# Defining Twitter access tokens
app_name <- "AirlineCustomerSatisfaction"
consumer_key <- "BujsomF1UhhKKWvITZOwF5Zsc"
consumer_secret <-"fTvj08eVKFFYXwxnWBms2RvZWtN5UISFr5utcDky2Ykux89aoR"
# Generating access token
twitter_token <- create_token(
app = app_name,
consumer_key,
consumer_secret)
# Getting tweet for airline
test <- search_tweets("@united OR #united", n=100000, lang = "en")
# Getting tweet for airline
test <- search_tweets("@united OR #united", n=1000, lang = "en")
View(test)
min(test$created_at)
library("xlsx")
install.packages("xlsx")
library("xlsx")
library("xlsx")
install.packages("RExcel")
library("RExcel")
install.packages("RExcel")
## install rtweet package if it's not already
if (!requireNamespace("rtweet", quietly = TRUE)) {
install.packages("rtweet")
}
# Load libraries
library("rtweet")
library("tidyverse")
library("stringr")
library("magrittr")
library("RExcel")
# Defining Twitter access tokens
app_name <- "AirlineCustomerSatisfaction"
# Defining Twitter access tokens
app_name <- "AirlineCustomerSatisfaction"
consumer_key <- "BujsomF1UhhKKWvITZOwF5Zsc"
consumer_secret <-"fTvj08eVKFFYXwxnWBms2RvZWtN5UISFr5utcDky2Ykux89aoR"
# Generating access token
twitter_token <- create_token(
app = app_name,
consumer_key,
consumer_secret)
# Defining airlines
airlines <- c("united", "alaskaair", "allegiant", "americanair",
"delta", "flyfrontier", "hawaiianair", "jetblue", "southwestair", "spiritairlines")
# Getting tweet for airline
getAirlineTweets <- function(i){
tweets <- search_tweets(paste("@",i," OR ", "#", i, sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE )
write.table(tweets, file = "airlineTweets.xlsx", append = TRUE)
}
sapply(airlines, getAirlineTweets)
library("readr")
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
tweets <- search_tweets(paste("@",i," OR ", "#", i, sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE )
tweets <- search_tweets(paste("@","united"," OR ", "#", "united", sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE )
View(tweets)
min(tweets$created_at)
str(tweets)
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
tweets <- search_tweets(paste("@","united"," OR ", "#", "united", sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE )
class(tweets)
airlineTweets <- sapply(airlines, getAirlineTweets)
View(airlineTweets)
?sapply
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
# Getting tweet for airline
getAirlineTweets <- function(i){
tweets <- search_tweets(paste("@",i," OR ", "#", i, sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE ) %>%
omit.na()
return(tweets)
}
airlineTweets <- sapply(airlines, getAirlineTweets, USE.NAMES = TRUE)
# Getting tweet for airline
getAirlineTweets <- function(i){
tweets <- search_tweets(paste("@",i," OR ", "#", i, sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE ) %>%
na.omit()
return(tweets)
}
airlineTweets <- sapply(airlines, getAirlineTweets, USE.NAMES = TRUE)
View(airlineTweets)
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
library("tidytext")
installed.packages("tidytext")
library("dplyr")
install.packages("tidytext")
library("tidytext")
airlineTweets <- sapply(airlines, getAirlineTweets, USE.NAMES = TRUE)
tweets <- search_tweets(paste("@","united"," OR ", "#", "united", sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE,
retryonratelimit = TRUE)
tweets <- search_tweets(paste("@","united"," OR ", "#", "united", sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE)
tweets <- search_tweets(paste("@","united"," OR ", "#", "united", sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE)
tweets <- search_tweets(paste("@","united"," OR ", "#", "united", sep = ""), n=1000,
lang = "en", geocode = lookup_coords("USA"),include_rts = FALSE)
source('~/GitHub/ieseDataSciTwitterProject/twitterAir.r')
